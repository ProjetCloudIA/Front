import streamlit as st
import pandas as pd
import requests
from PIL import Image
import io
import cv2
import numpy as np
import time
import streamlit as st
import asyncio
import websockets
import base64
import json

st.title('Emotion Detection')

with st.form(key="my_form"):
    uploaded_file = st.file_uploader('Upload a file', type=['png', 'jpg', 'jpeg'])
    if(uploaded_file):
        image = Image.open(uploaded_file)
        img_bytes = io.BytesIO()
        image.save(img_bytes, format=image.format)
        img_bytes = img_bytes.getvalue()
        try:
            response = requests.post("https://api-cloud-dfc87ab4de89.herokuapp.com/predict", files={"file": img_bytes})
            result = response.json()['prediction'][0]

            if(result=="surprise"):
                st.success('Surprise ğŸ˜¯')
            elif(result=="sad"):
                st.success('Sad ğŸ˜­')
            elif(result=="neutral"):
                st.success('Neutral ğŸ˜')
            elif(result=="happy"):
                st.success('Happy ğŸ˜Š')
            elif(result=="fear"):
                st.success('Fear ğŸ˜¨')
            elif(result=="disgust"):
                st.success('Disgust ğŸ¤¢')
            elif(result=="angry"):
                st.success('Angry ğŸ˜¡')
            
        except:
            st.error('Failed to create a new record')
    st.form_submit_button("Predict")


# URL du WebSocket de l'API FastAPI
WS_URL = "ws://api-cloud-g1-177dac7611b1.herokuapp.com/ws"  # Remplace par l'URL correcte

st.title("ğŸ¥ Flux VidÃ©o en Direct + PrÃ©diction")

# Conteneur pour afficher l'image et la prÃ©diction
image_placeholder = st.empty()
prediction_placeholder = st.empty()

async def stream_video():
    """Envoie les images de la webcam Ã  l'API WebSocket et affiche la prÃ©diction."""
    async with websockets.connect(WS_URL) as websocket:
        cap = cv2.VideoCapture(0)  # Ouvre la webcam

        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break

                # Convertir l'image OpenCV en PIL
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                image_pil = Image.fromarray(frame_rgb)

                # Encoder l'image en binaire
                img_bytes = io.BytesIO()
                image_pil.save(img_bytes, format="JPEG")
                img_bytes = img_bytes.getvalue()

                # Envoyer l'image Ã  l'API WebSocket
                await websocket.send(img_bytes)

                # RÃ©ception de la prÃ©diction
                response = await websocket.recv()
                prediction = json.loads(response).get("prediction", "Aucune prÃ©diction")

                # Mise Ã  jour de l'affichage Streamlit
                image_placeholder.image(image_pil, caption="Flux en direct", use_container_width=True)
                result_stream = prediction[0]
                text_to_write = ''
                if(result_stream=="surprise"):
                    text_to_write='Surprise ğŸ˜¯'
                elif(result_stream=="sad"):
                    text_to_write='Sad ğŸ˜­'
                elif(result_stream=="neutral"):
                    text_to_write='Neutral ğŸ˜'
                elif(result_stream=="happy"):
                    text_to_write='Happy ğŸ˜Š'
                elif(result_stream=="fear"):
                    text_to_write='Fear ğŸ˜¨'
                elif(result_stream=="disgust"):
                    text_to_write='Disgust ğŸ¤¢'
                elif(result_stream=="angry"):
                    text_to_write='Angry ğŸ˜¡'
                prediction_placeholder.write(f"**PrÃ©diction :** {text_to_write}")

                # await asyncio.sleep(0.05)  # Pause pour Ã©viter de surcharger l'API

        finally:
            cap.release()

# Lancer la boucle d'Ã©vÃ©nements Asyncio
asyncio.run(stream_video())



